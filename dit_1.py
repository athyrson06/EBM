import dit
from dit import Distribution
from dit.multivariate import PID_GK

# Definindo a distribui√ß√£o conjunta das vari√°veis (X0, X1, Y)
# Y = X0 XOR X1

data = [
    ((0, 0, 0), 0.25),
    ((0, 1, 1), 0.25),
    ((1, 0, 1), 0.25),
    ((1, 1, 0), 0.25),
]

# Criando a distribui√ß√£o no dit
d = Distribution(data)
d.set_rv_names(['X0', 'X1', 'Y'])

# Partial Information Decomposition (Griffith-Koch method)
pid = PID_GK(d, ['X0', 'X1'], 'Y')

# üîç Mostrando os componentes da decomposi√ß√£o
print("Partial Information Decomposition (PID):")
print(f"  Redundant info     : {pid.get_partial('redundant'):.3f}")
print(f"  Unique info X0     : {pid.get_partial(('X0',)):.3f}")
print(f"  Unique info X1     : {pid.get_partial(('X1',)):.3f}")
print(f"  Synergistic info   : {pid.get_partial('synergy'):.3f}")
print()

# üîé Comparando com a informa√ß√£o m√∫tua total
from dit.multivariate import mutual_information as MI

mi = MI(d, ['X0', 'X1'], 'Y')
print(f"Total Mutual Information I([X0,X1]; Y): {mi:.3f}")
